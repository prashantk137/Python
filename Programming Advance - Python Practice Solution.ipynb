{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f47d3ad",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cb764e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T07:40:15.243455Z",
     "start_time": "2022-06-15T07:40:15.219921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a code for printing factorial of a number using recursion\n",
    "\n",
    "def factorial(N):\n",
    "    '''\n",
    "    A factorial of N is defined as \n",
    "\n",
    "    N * (N-1) * (N-2) * (N-3) * (N-4) ... 1 \n",
    "\n",
    "    example:\n",
    "        factorial of 4 is = `4*3*2*1 = 24` \n",
    "    '''\n",
    "    if N==1:\n",
    "        return 1 \n",
    "    else:\n",
    "        return N*factorial(N-1)\n",
    "    \n",
    "factorial(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ced10",
   "metadata": {},
   "source": [
    "# Question 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14f81ee4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T07:40:19.264133Z",
     "start_time": "2022-06-15T07:40:19.232129Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 9,\n",
       " 11,\n",
       " 13,\n",
       " 15,\n",
       " 17,\n",
       " 19,\n",
       " 21,\n",
       " 23,\n",
       " 25,\n",
       " 27,\n",
       " 29,\n",
       " 31,\n",
       " 33,\n",
       " 35,\n",
       " 37,\n",
       " 39,\n",
       " 41,\n",
       " 43,\n",
       " 45,\n",
       " 47,\n",
       " 49,\n",
       " 51,\n",
       " 53,\n",
       " 55,\n",
       " 57,\n",
       " 59,\n",
       " 61,\n",
       " 63,\n",
       " 65,\n",
       " 67,\n",
       " 69,\n",
       " 71,\n",
       " 73,\n",
       " 75,\n",
       " 77,\n",
       " 79,\n",
       " 81,\n",
       " 83,\n",
       " 85,\n",
       " 87,\n",
       " 89,\n",
       " 91,\n",
       " 93,\n",
       " 95,\n",
       " 97,\n",
       " 99]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a lambda code for checking if a number if even or odd and then use it to filter odd numbers from a given list\n",
    "\n",
    "checker = lambda x : True if x%2 ==1 else False\n",
    "s=range(0,100,1)\n",
    "filtered_list = list(filter(checker,s))\n",
    "filtered_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab616970",
   "metadata": {},
   "source": [
    "# Question 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "690a339f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T07:40:23.227614Z",
     "start_time": "2022-06-15T07:40:23.211608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a file containing factors of number 5000, make sure each factor is written in a different line\n",
    "\n",
    "N=5000\n",
    "factors = ''\n",
    "\n",
    "for x in range(1,(N//2) +1):\n",
    "    if N%x==0:\n",
    "        factors=factors+str(x)+\"\\n\"\n",
    "\n",
    "factors = factors + str(N)\n",
    "with open('factorsOf5000.txt','w') as f:\n",
    "    f.write(factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab1033",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5df52df7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T07:40:34.346203Z",
     "start_time": "2022-06-15T07:40:26.310354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the github username:akashgandhi51\n",
      "Project Number: 1\n",
      "Project Name: Outlier-Detection\n",
      "Project URL: https://github.com/akashgandhi51/Outlier-Detection \n",
      "\n",
      "Project Number: 2\n",
      "Project Name: Missing-Data-Imputation\n",
      "Project URL: https://github.com/akashgandhi51/Missing-Data-Imputation \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Some additional git hub public apis \n",
    "\n",
    "import requests\n",
    "username = input(\"Enter the github username:\")\n",
    "request = requests.get('https://api.github.com/users/'+username+'/starred')\n",
    "json = request.json()\n",
    "for i in range(0,len(json)):\n",
    "#     print(json[i])\n",
    "    print(\"Project Number:\",i+1)\n",
    "    print(\"Project Name:\",json[i]['name'])\n",
    "    print(\"Project URL:\",json[i]['svn_url'],\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1eaf24f",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4839e974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-15T07:40:40.001238Z",
     "start_time": "2022-06-15T07:40:37.336953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# Create a code which Queries reddit/twitter html pages and store the outputs using multi threaded code\n",
    "import requests\n",
    "import uuid\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "pagelist=['https://twitter.com/TechNation','https://twitter.com/Apple','https://twitter.com/MKBHD','https://www.reddit.com/r/artificial/','https://www.reddit.com/r/Volvo/','https://www.reddit.com/r/technology/']\n",
    "\n",
    "\n",
    "def filedownloader(url,filename):\n",
    "    try:\n",
    "        html=requests.get(url,stream=True)\n",
    "        open(f'{filename}.txt','wb').write(html.content)\n",
    "        return html.status_code\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return e\n",
    "\n",
    "def thread():\n",
    "    threads= []\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        for url in pagelist:\n",
    "            file_name = uuid.uuid1()\n",
    "            threads.append(executor.submit(filedownloader, url, file_name))\n",
    "\n",
    "        for task in as_completed(threads):\n",
    "            print(task.result()) \n",
    "    \n",
    "with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    thread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b98d56f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-10T07:37:02.155050Z",
     "start_time": "2022-06-10T07:37:01.247984Z"
    }
   },
   "outputs": [],
   "source": [
    "### Alternate Way to get data using Reddit APIs\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "\n",
    "# Acessing the reddit api\n",
    "reddit = praw.Reddit(client_id=\"\",#my client id\n",
    "                     client_secret=\"\",  #your client secret\n",
    "                     user_agent=\"my user agent\", #user agent name\n",
    "                     username = \"\",     # your reddit username\n",
    "                     password = \"\")     # your reddit password\n",
    "### Note: How to get the above values: \n",
    "# https://www.geeksforgeeks.org/how-to-get-client_id-and-client_secret-for-python-reddit-api-registration/\n",
    "\n",
    "sub = ['Askreddit']  # make a list of subreddits you want to scrape the data from\n",
    "\n",
    "for s in sub:\n",
    "    subred = reddit.subreddit(s)   # Chosing the subreddit\n",
    "\n",
    "########################################\n",
    "#   CREATING DICTIONARY TO STORE THE DATA WHICH WILL BE CONVERTED TO A DATAFRAME\n",
    "########################################\n",
    "\n",
    "#   NOTE: ALL THE POST DATA AND COMMENT DATA WILL BE SAVED IN TWO DIFFERENT\n",
    "#   DATASETS AND LATER CAN BE MAPPED USING IDS OF POSTS/COMMENTS AS WE WILL \n",
    "#   BE CAPTURING ALL IDS THAT COME IN OUR WAY\n",
    "\n",
    "# SCRAPING CAN BE DONE VIA VARIOUS STRATEGIES {HOT,TOP,etc} we will go with keyword strategy i.e using search a keyword\n",
    "    query = ['DataScience']\n",
    "\n",
    "    for item in query:\n",
    "        post_dict = {\n",
    "            \"title\" : [],\n",
    "            \"score\" : [],\n",
    "            \"id\" : [],\n",
    "            \"url\" : [],\n",
    "            \"comms_num\": [],\n",
    "            \"created\" : [],\n",
    "            \"body\" : []\n",
    "        }\n",
    "        comments_dict = {\n",
    "            \"comment_id\" : [],\n",
    "            \"comment_parent_id\" : [],\n",
    "            \"comment_body\" : [],\n",
    "            \"comment_link_id\" : []\n",
    "        }\n",
    "        for submission in subred.search(query,sort = \"top\",limit = 1):\n",
    "            post_dict[\"title\"].append(submission.title)\n",
    "            post_dict[\"score\"].append(submission.score)\n",
    "            post_dict[\"id\"].append(submission.id)\n",
    "            post_dict[\"url\"].append(submission.url)\n",
    "            post_dict[\"comms_num\"].append(submission.num_comments)\n",
    "            post_dict[\"created\"].append(submission.created)\n",
    "            post_dict[\"body\"].append(submission.selftext)\n",
    "            \n",
    "            ##### Acessing comments on the post\n",
    "            submission.comments.replace_more(limit = 1)\n",
    "            for comment in submission.comments.list():\n",
    "                comments_dict[\"comment_id\"].append(comment.id)\n",
    "                comments_dict[\"comment_parent_id\"].append(comment.parent_id)\n",
    "                comments_dict[\"comment_body\"].append(comment.body)\n",
    "                comments_dict[\"comment_link_id\"].append(comment.link_id)\n",
    "        \n",
    "        post_comments = pd.DataFrame(comments_dict)\n",
    "\n",
    "        post_comments.to_csv(s+\"_comments_\"+ item +\"subreddit.csv\")\n",
    "        post_data = pd.DataFrame(post_dict)\n",
    "        post_data.to_csv(s+\"_\"+ item +\"subreddit.csv\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
